# ğŸ§  LLM Chatbot with FastAPI + Streamlit + Groq API

A lightweight, full-stack AI chatbot built using **FastAPI** as a backend, **Streamlit** for the frontend UI, and integrated with **Groqâ€™s blazing-fast inference API** serving Meta's LLaMA 3 model.

---

## ğŸš€ Live Demo

- **Frontend UI (Streamlit)** ğŸ‘‰ [Try it live](https://fastapi-app-groq-chatbot-cgqwslw2kbyed4bfdhr2tm.streamlit.app/)
- **Backend API (FastAPI)** ğŸ‘‰ [Open API base](https://fastapi-streamlit-groq-chatbot.onrender.com/)

---

## ğŸ›  Tech Stack

| Layer       | Tech         |
|-------------|--------------|
| UI          | Streamlit    |
| Backend API | FastAPI      |
| AI Model    | LLaMA 3 (via Groq API) |
| Hosting     | Streamlit Cloud (frontend) & Render (backend) |
| Language    | Python 3.10+ |
| Dependency  | `openai`, `requests`, `pydantic`, `fastapi`, `python-dotenv`, `uvicorn` |

---

## ğŸ“¦ Project Structure

```bash
FastAPI_Chatbot/
â”œâ”€â”€ .env                      # API Keys and model config (not tracked in Git)
â”œâ”€â”€ main.py                   # FastAPI backend: Receives chat, calls Groq API
â”œâ”€â”€ streamlit_app.py          # Frontend UI: Sends requests to FastAPI endpoint
â”œâ”€â”€ requirements.txt          # All dependencies
â””â”€â”€ README.md                 # You're reading it!
```


## ğŸ§  How It Works
- `main.py`: FastAPI server receives user questions, attaches minimal history, and forwards it to the Groq API.
- `streamlit_app.py`: Streamlit UI handles user interaction and displays responses from the FastAPI backend.
- Uses session memory and concise formatting to keep UX clean and fast.

## âœ¨ Features
- âš¡ Super fast responses (thanks to Groq's low-latency inference).
- ğŸ§  Context-aware replies with minimal memory to avoid bloated prompts.
- ğŸ—ƒï¸ Downloadable chat transcripts.
- âœ… Clearly separated backend/frontend for easy scaling.
- â˜ï¸ Cloud deployment on Streamlit Cloud and Render for zero-cost hosting.

## ğŸ“¤ Deployment 
- FastAPI Backend â†’ [Render.com](https://render.com/docs/deploy-fastapi/)
- Streamlit Frontend â†’ [Streamlit Cloud](https://streamlit.io/cloud)

## ğŸ™Œ Credits
- [Meta](https://ai.meta.com/llama/) for LLaMA 3
- [Groq](https://groq.com/) for free blazing-fast API access
- [Streamlit](https://streamlit.io/) & [FastAPI](https://fastapi.tiangolo.com/)

## ğŸ§‘â€ğŸ’» Author
- Deepak Siriboyina â€“ [LinkedIn](https://www.linkedin.com/in/deepak-siriboyina/)
